{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##  ewf-ext-03-03-03 - Flood hazard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'ewf-ext-03-03-03 - Flood exposure'),\n",
    "                ('abstract', 'ewf-ext-03-03-03 - Flood exposure'),\n",
    "                ('id', 'ewf-ext-03-03-03')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = dict([('id', 'start_year'),\n",
    "            ('value', '2015'),\n",
    "            ('title', 'start year'),\n",
    "            ('abstract', 'start year')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_year = dict([('id', 'end_year'),\n",
    "            ('value', '2019'),\n",
    "            ('title', 'end_year'),\n",
    "            ('abstract', 'end_year')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_interest = dict([('id', 'areaOfInterest'),\n",
    "                         ('value', 'IberianPeninsula'),\n",
    "                         ('title', 'Area of the region'),\n",
    "                         ('abstract', 'Area of the region of interest')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionOfInterest = dict([('id', 'regionOfInterest'),\n",
    "                         ('value', '-1'),\n",
    "                         ('title', 'WKT Polygon for the Region of Interest (-1 if no crop)'),\n",
    "                         ('abstract', 'Set the value of WKT Polygon')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "This is the Sentinel-1 stack of products' identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_identifiers = ('GHS_POP_E2015_GLOBE_R2019A_54009_250_V1_0_17_4.tif', 'U2018_CLC2018_V2020_20u1.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "This is the Sentinel-1 stack catalogue references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "input_references = ('https://catalog.terradue.com/chirps/search?format=atom&uid=chirps-v2.0.2017.01.01','https://catalog.terradue.com/chirps/search?format=atom&uid=chirps-v2.0.2017.01.02') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/workspace/data/Copernicus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#etc_path = \"/application/notebook/etc\"\n",
    "etc_path = \"/workspace/Better_3rd_phase/Applications/EXT-03-03-02/ewf-ext-03-03-02/src/main/app-resources/notebook/etc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_folder = \"\"\n",
    "output_folder = \"/workspace/Better_3rd_phase/Applications/EXT-03-03-03/ewf-ext-03-03-03/src/main/app-resources/notebook/libexec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = 'Temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_output_folder = 'Output/Crop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "from osgeo import gdal, ogr, osr\n",
    "from shapely.wkt import loads\n",
    "import datetime\n",
    "import gdal\n",
    "\n",
    "import pdb\n",
    "from calendar import monthrange\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# remove contents of a given folder\n",
    "# used to clean a temporary folder\n",
    "def rm_cfolder(folder):\n",
    "    #folder = '/path/to/folder'\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "def crop_image(input_image, polygon_wkt, output_path, product_type=None):\n",
    "    \n",
    "    dataset = None\n",
    "        \n",
    "    if input_image.startswith('ftp://') or input_image.startswith('http'):\n",
    "        try:\n",
    "            dataset = gdal.Open('/vsigzip//vsicurl/%s' % input_image)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    elif '.nc' in input_image:\n",
    "        dataset = gdal.Open('NETCDF:' + input_image + ':' + product_type)\n",
    "\n",
    "    polygon_ogr = ogr.CreateGeometryFromWkt(polygon_wkt)\n",
    "    envelope = polygon_ogr.GetEnvelope()\n",
    "    bounds = [envelope[0], envelope[3], envelope[1], envelope[2]]         \n",
    "\n",
    "    gdal.Translate(output_path, dataset, outputType=gdal.GDT_Int16, projWin=bounds, projWinSRS='EPSG:4326')\n",
    "\n",
    "    dataset = None\n",
    "\n",
    "    \n",
    "def write_output_image(filepath, output_matrix, image_format, data_format, mask=None, output_projection=None, output_geotransform=None, no_data_value=None):\n",
    "    driver = gdal.GetDriverByName(image_format)\n",
    "    out_rows = np.size(output_matrix, 0)\n",
    "    out_columns = np.size(output_matrix, 1)\n",
    "    \n",
    "    \n",
    "    if mask is not None and mask is not 0:\n",
    "        # TODO: check if output folder exists\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 2, data_format)\n",
    "        mask_band = output.GetRasterBand(2)\n",
    "        mask_band.WriteArray(mask)\n",
    "        if no_data_value is not None:\n",
    "            output_matrix[mask > 0] = no_data_value\n",
    "    else:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 1, data_format)\n",
    "    \n",
    "    if output_projection is not None:\n",
    "        output.SetProjection(output_projection)\n",
    "    if output_geotransform is not None:\n",
    "        output.SetGeoTransform(output_geotransform)\n",
    "    \n",
    "    raster_band = output.GetRasterBand(1)\n",
    "    if no_data_value is not None:\n",
    "        raster_band.SetNoDataValue(no_data_value)\n",
    "    raster_band.WriteArray(output_matrix)\n",
    "    \n",
    "    if filepath is None:\n",
    "        print  \"filepath\"\n",
    "    if output is None:\n",
    "        print  \"output\"\n",
    "    gdal.Warp(filepath, output, format=\"GTiff\", outputBoundsSRS='EPSG:4326', xRes=output_geotransform[1], yRes=-output_geotransform[5], targetAlignedPixels=True)\n",
    "\n",
    "    return filepath\n",
    "\n",
    "\n",
    "def matrix_multiply(mat1, mat2, no_data_value=None):\n",
    "    #if no_data_value is not None:\n",
    "        #if not isinstance(mat1, int):\n",
    "            #mat1[(mat1 == no_data_value)] = 0\n",
    "        #if not isinstance(mat2, int):\n",
    "            #mat2[(mat2 == no_data_value)] = 0\n",
    "    mats_nodata = np.logical_or(mat1 == no_data_value, mat2 == no_data_value)\n",
    "    mat1 = mat1.astype('float32')\n",
    "    mat2 = mat2.astype('float32')\n",
    "    multiply = mat1 * mat2\n",
    "    multiply = np.where(mats_nodata, no_data_value, multiply)\n",
    "    return multiply\n",
    "            \n",
    "\n",
    "'''def get_matrix_list(image_list, product_type):\n",
    "    projection = None\n",
    "    geo_transform = None\n",
    "    no_data = None\n",
    "    mat_list = []\n",
    "    for img in image_list:\n",
    "        dataset = gdal.Open('NETCDF:' + img + ':' + product_type)\n",
    "        projection = dataset.GetProjection()\n",
    "        geo_transform = dataset.GetGeoTransform()\n",
    "        no_data = dataset.GetRasterBand(1).GetNoDataValue()\n",
    "        product_array = dataset.GetRasterBand(1).ReadAsArray()\n",
    "        mat_list.append(product_array)\n",
    "        dataset = None\n",
    "    return mat_list, projection, geo_transform, no_data'''\n",
    "\n",
    "def get_matrix_list(image_list):\n",
    "    projection = None\n",
    "    geo_transform = None\n",
    "    no_data = None\n",
    "    mat_list = []\n",
    "    for img in image_list:\n",
    "        dataset = gdal.Open(img)\n",
    "        print dataset\n",
    "        projection = dataset.GetProjection()\n",
    "        print projection\n",
    "        geo_transform = dataset.GetGeoTransform()\n",
    "        no_data = dataset.GetRasterBand(1).GetNoDataValue()\n",
    "        product_array = dataset.GetRasterBand(1).ReadAsArray()\n",
    "        mat_list.append(product_array)\n",
    "        dataset = None\n",
    "    return mat_list, projection, geo_transform, no_data\n",
    "    \n",
    "def write_outputs(product_name, first_date, last_date, averages, standard_deviation, image_format, projection, geo_transform, no_data_value):\n",
    "    filenames = []\n",
    "    areaofinterest = area_of_interest['value']\n",
    "    filenames.append(product_name + '_averages_' + areaofinterest + '_' + first_date + '_' + last_date + '.tif')\n",
    "    filenames.append(product_name + '_standarddeviation_' + areaofinterest + '_'+ first_date + '_' + last_date + '.tif')\n",
    "\n",
    "    write_output_image(filenames[0], averages, image_format, gdal.GDT_Int16, None, projection, geo_transform, no_data_value)\n",
    "    write_output_image(filenames[1], standard_deviation, image_format, gdal.GDT_Int16, None, projection, geo_transform, no_data_value)\n",
    "    \n",
    "    return filenames\n",
    "\n",
    "def write_properties_file(output_name, first_date, last_date):\n",
    "    \n",
    "    title = 'Output %s' % output_name\n",
    "    \n",
    "    first_date = get_formatted_date(first_date)\n",
    "    last_date = get_formatted_date(last_date)\n",
    "    \n",
    "    with open(output_name + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (first_date, last_date))\n",
    "        file.write('geometry=%s' % (regionOfInterest['value']))\n",
    "        \n",
    "def get_formatted_date(date_obj):\n",
    "    date = datetime.datetime.strftime(date_obj, '%Y-%m-%dT00:00:00Z')\n",
    "    return date\n",
    "\n",
    "def reproject_image_to_master ( master, slave, dst_filename, res=None ):\n",
    "\n",
    "    slave_ds = gdal.Open( slave )\n",
    "    if slave_ds is None:\n",
    "        raise IOError, \"GDAL could not open slave file %s \" \\\n",
    "            % slave\n",
    "    slave_proj = slave_ds.GetProjection()\n",
    "    slave_geotrans = slave_ds.GetGeoTransform()\n",
    "    data_type = slave_ds.GetRasterBand(1).DataType\n",
    "    n_bands = slave_ds.RasterCount\n",
    "\n",
    "    master_ds = gdal.Open( master )\n",
    "    if master_ds is None:\n",
    "        raise IOError, \"GDAL could not open master file %s \" \\\n",
    "            % master\n",
    "    master_proj = master_ds.GetProjection()\n",
    "    master_geotrans = master_ds.GetGeoTransform()\n",
    "    w = master_ds.RasterXSize\n",
    "    h = master_ds.RasterYSize\n",
    "    \n",
    "    if res is not None:\n",
    "        master_geotrans[1] = float( res )\n",
    "        master_geotrans[-1] = - float ( res )\n",
    "    \n",
    "    dst_ds = gdal.GetDriverByName('GTiff').Create(dst_filename, w, h, n_bands, data_type)\n",
    "    \n",
    "    dst_ds.SetGeoTransform( master_geotrans )\n",
    "    dst_ds.SetProjection( master_proj)\n",
    "    \n",
    "    gdal.ReprojectImage( slave_ds, dst_ds, slave_proj,\n",
    "                         master_proj, gdal.GRA_NearestNeighbour)\n",
    "    \n",
    "    dst_ds = None  # Flush to disk\n",
    "    \n",
    "    return dst_filename\n",
    "\n",
    "def project_coordinates(file, dst_filename):\n",
    "    input_raster = gdal.Open(file)\n",
    "    output_raster = dst_filename \n",
    "    gdal.Warp(output_raster,input_raster,dstSRS='EPSG:4326')\n",
    "    \n",
    "def get_pixel_weights(mat):\n",
    "    urban_fabric=[111.,112.]\n",
    "    industrial_commercial_transport_units=[121.,122.,123.,124.]\n",
    "    mine_dump_construction_sites=[131.,132.,133.]\n",
    "    artificial_areas=[141.,142.]\n",
    "    arable_land=[211.,212.,213.]\n",
    "    permanent_crops=[221.,222.,223.]\n",
    "    pastures=[231.]\n",
    "    agricultural_areas=[241.,242.,243.,244.]\n",
    "    forest=[311.,312.,313.]\n",
    "    vegetation_associations=[321.,322.,323.,324.]\n",
    "    little_no_vegetation=[331.,332.,333.,334.,335.]\n",
    "    inland_wetlands=[411.,412.]\n",
    "    coastal_wetlands=[421.,422.,423.]\n",
    "    inland_waters=[511.,512.]\n",
    "    marine_waters=[521.,522.,523.]\n",
    "\n",
    "    exposure_dictionary = dict()\n",
    "    exposure_dictionary[1.0] = urban_fabric\n",
    "    exposure_dictionary[0.5] = industrial_commercial_transport_units + arable_land + permanent_crops\n",
    "    exposure_dictionary[0.3] = mine_dump_construction_sites + agricultural_areas\n",
    "    exposure_dictionary[0.0] = artificial_areas + marine_waters\n",
    "    exposure_dictionary[0.4] = pastures\n",
    "    exposure_dictionary[0.1] = forest + vegetation_associations + little_no_vegetation + inland_wetlands + coastal_wetlands + inland_waters\n",
    "\n",
    "    rows = mat.shape[0]\n",
    "    cols = mat.shape[1]\n",
    "\n",
    "    for i in range(0, rows):\n",
    "        for j in range(0, cols):\n",
    "            for exposure, value_list in exposure_dictionary.iteritems():\n",
    "                for value in value_list:\n",
    "                    if mat[i,j] == value:\n",
    "                        mat[i,j] = exposure\n",
    "    return mat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(output_folder) > 0:\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "\n",
    "if not os.path.isdir(temp_folder):\n",
    "    os.mkdir(temp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('IberianPeninsula', '2015', '2019')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_of_interest['value'], start_year['value'], end_year['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update AOI if crop not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_products = ('GHS_POP_E2015_GLOBE_R2019A_54009_250_V1_0_17_4.tif', 'U2018_CLC2018_V2020_20u1.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Better_3rd_phase/Applications/EXT-03-03-02/ewf-ext-03-03-02/src/main/app-resources/notebook/etc/GHS_POP_E2015_GLOBE_R2019A_54009_250_V1_0_17_4.tif\n",
      "<osgeo.gdal.Dataset; proxy of <Swig Object of type 'GDALDatasetShadow *' at 0x7f23fab829c0> >\n",
      "PROJCS[\"World_Mollweide\",GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.017453292519943295]],PROJECTION[\"Mollweide\"],PARAMETER[\"False_Easting\",0.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",0.0],UNIT[\"Meter\",1.0]]\n",
      "<osgeo.gdal.Dataset; proxy of <Swig Object of type 'GDALDatasetShadow *' at 0x7f23fab829c0> >\n",
      "PROJCS[\"ETRS_1989_LAEA\",GEOGCS[\"ETRS89\",DATUM[\"European_Terrestrial_Reference_System_1989\",SPHEROID[\"GRS 1980\",6378137,298.2572221010042,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6258\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4258\"]],PROJECTION[\"Lambert_Azimuthal_Equal_Area\"],PARAMETER[\"latitude_of_center\",52],PARAMETER[\"longitude_of_center\",10],PARAMETER[\"false_easting\",4321000],PARAMETER[\"false_northing\",3210000],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AUTHORITY[\"EPSG\",\"3035\"]]\n",
      "[array([[-200., -200., -200., ...,    0.,    0.,    0.],\n",
      "       [-200., -200., -200., ...,    0.,    0.,    0.],\n",
      "       [-200., -200., -200., ...,    0.,    0.,    0.],\n",
      "       ..., \n",
      "       [-200., -200., -200., ...,    0.,    0.,    0.],\n",
      "       [-200., -200., -200., ...,    0.,    0.,    0.],\n",
      "       [-200., -200., -200., ...,    0.,    0.,    0.]], dtype=float32), array([[-128, -128, -128, ..., -128, -128, -128],\n",
      "       [-128, -128, -128, ..., -128, -128, -128],\n",
      "       [-128, -128, -128, ..., -128, -128, -128],\n",
      "       ..., \n",
      "       [-128, -128, -128, ..., -128, -128, -128],\n",
      "       [-128, -128, -128, ..., -128, -128, -128],\n",
      "       [-128, -128, -128, ..., -128, -128, -128]], dtype=int8)]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4000,4000) (46000,65000) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-6e4e27406488>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mflood_frequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mflood_exposure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mflood_hazard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix_multiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflood_frequency\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflood_exposure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrite_output_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_path_name\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'FEI_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mareaofinterest\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_GHS_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfirst_year\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_CLC_'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mlast_year\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.tif'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflood_hazard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GTiff'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGDT_Float32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeo_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-43d3feb6a8eb>\u001b[0m in \u001b[0;36mmatrix_multiply\u001b[0;34m(mat1, mat2, no_data_value)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m#if not isinstance(mat2, int):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;31m#mat2[(mat2 == no_data_value)] = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mmats_nodata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mno_data_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mno_data_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mmat1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mmat2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4000,4000) (46000,65000) "
     ]
    }
   ],
   "source": [
    "first_year = start_year['value']\n",
    "last_year = end_year['value']\n",
    "product_path_name = output_folder\n",
    "projection = None\n",
    "geo_transform = None\n",
    "no_data = None\n",
    "areaofinterest = area_of_interest['value']\n",
    "\n",
    "if input_products[0] >=0:    \n",
    "        file_list = [os.path.join(etc_path, filename) for filename in input_products]\n",
    "        print file_list[0]\n",
    "        mat_list, projection, geo_transform, no_data = get_matrix_list(file_list)\n",
    "        print mat_list\n",
    "\n",
    "        flood_frequency = mat_list[0]\n",
    "        flood_exposure = mat_list[1]\n",
    "        flood_hazard = matrix_multiply(flood_frequency,flood_exposure, no_data)\n",
    "        \n",
    "        file = write_output_image(os.path.join(product_path_name , 'FEI_' + areaofinterest + '_GHS_' + first_year + '_CLC_'+ last_year + '.tif'), flood_hazard, 'GTiff', gdal.GDT_Float32, None, projection, geo_transform, no_data)\n",
    "        firstdate_obj = datetime.datetime.strptime(first_year, \"%Y\").date()\n",
    "        lastdate_obj = datetime.datetime.strptime(last_year, \"%Y\").date()\n",
    "        \n",
    "else:\n",
    "        print \"error\" + file_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "not a string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-237f534c94db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m#dataset = gdal.Open('/vsigzip//vsicurl/%s' % gpd_final.iloc[0]['enclosure'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mgeoTransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetGeoTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/osgeo/gdal.pyc\u001b[0m in \u001b[0;36mOpen\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3017\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m     \u001b[0;34m\"\"\"Open(char const * utf8_path, GDALAccess eAccess) -> Dataset\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_gdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mOpenEx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: not a string"
     ]
    }
   ],
   "source": [
    "if input_products[0] >=0:    \n",
    "    if regionOfInterest['value'] == '-1':\n",
    "\n",
    "        #dataset = gdal.Open('/vsigzip//vsicurl/%s' % gpd_final.iloc[0]['enclosure'])\n",
    "        dataset = gdal.Open(file)\n",
    "\n",
    "        geoTransform = dataset.GetGeoTransform()\n",
    "\n",
    "        minx = geoTransform[0]\n",
    "        maxy = geoTransform[3]\n",
    "        maxx = minx + geoTransform[1] * dataset.RasterXSize\n",
    "        miny = maxy + geoTransform[5] * dataset.RasterYSize\n",
    "\n",
    "        regionOfInterest['value'] = 'POLYGON(({0} {1}, {2} {1}, {2} {3}, {0} {3}, {0} {1}))'.format(minx, maxy, maxx, miny)\n",
    "\n",
    "        dataset = None\n",
    "\n",
    "    regionofinterest = regionOfInterest['value']\n",
    "    write_properties_file(file, firstdate_obj, lastdate_obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove temporay files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree(temp_folder)\n",
    "    shutil.rmtree(cropped_output_folder)\n",
    "except OSError as e:\n",
    "    print(\"Error: %s : %s\" % (temp_folder, e.strerror))\n",
    "    print(\"Error: %s : %s\" % (cropped_output_folder, e.strerror))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
