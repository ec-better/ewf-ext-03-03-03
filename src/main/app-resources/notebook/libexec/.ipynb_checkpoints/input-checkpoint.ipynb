{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##  ewf-ext-03-03-03 - Flood hazard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'ewf-ext-03-03-03 - Flood exposure'),\n",
    "                ('abstract', 'ewf-ext-03-03-03 - Flood exposure'),\n",
    "                ('id', 'ewf-ext-03-03-03')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = dict([('id', 'start_year'),\n",
    "            ('value', '2015'),\n",
    "            ('title', 'start year'),\n",
    "            ('abstract', 'start year')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_year = dict([('id', 'end_year'),\n",
    "            ('value', '2019'),\n",
    "            ('title', 'end_year'),\n",
    "            ('abstract', 'end_year')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_interest = dict([('id', 'areaOfInterest'),\n",
    "                         ('value', 'IberianPeninsula'),\n",
    "                         ('title', 'Area of the region'),\n",
    "                         ('abstract', 'Area of the region of interest')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionOfInterest = dict([('id', 'regionOfInterest'),\n",
    "                         ('value', 'POLYGON((-9.586 39.597,-8.100 39.597,-8.100 40.695,-9.586 40.695,-9.586 39.597))'),\n",
    "                         ('title', 'WKT Polygon for the Region of Interest (-1 if no crop)'),\n",
    "                         ('abstract', 'Set the value of WKT Polygon')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "This is the Sentinel-1 stack of products' identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_identifiers = ('FEI_IberianPeninsula_GHS_2015_CLC_2019.tif', 'binary_flood_map_S1A_IW_GRDH_1SDV_20191223T064251_20191223T064316_030472_037D16_1012.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "This is the Sentinel-1 stack catalogue references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "input_references = ('https://catalog.terradue.com/chirps/search?format=atom&uid=chirps-v2.0.2017.01.01','https://catalog.terradue.com/chirps/search?format=atom&uid=chirps-v2.0.2017.01.02') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc_path = \"/application/notebook/etc\"\n",
    "#etc_path = \"/workspace/Better_3rd_phase/Applications/EXT-03-03-03/ewf-ext-03-03-03/src/main/app-resources/notebook/etc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"\"\n",
    "#output_folder = \"/workspace/Better_3rd_phase/Applications/EXT-03-03-03/ewf-ext-03-03-03/src/main/app-resources/notebook/libexec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = 'Temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_output_folder = 'Output/Crop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "from osgeo import gdal, ogr, osr\n",
    "from shapely.wkt import loads\n",
    "import datetime\n",
    "import gdal\n",
    "\n",
    "import pdb\n",
    "from calendar import monthrange\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# remove contents of a given folder\n",
    "# used to clean a temporary folder\n",
    "def rm_cfolder(folder):\n",
    "    #folder = '/path/to/folder'\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "def crop_image(input_image, polygon_wkt, output_path):\n",
    "    \n",
    "    dataset = gdal.Open(input_image)\n",
    "\n",
    "    polygon_ogr = ogr.CreateGeometryFromWkt(polygon_wkt)\n",
    "    envelope = polygon_ogr.GetEnvelope()\n",
    "    bounds = [envelope[0], envelope[3], envelope[1], envelope[2]]         \n",
    "    print bounds\n",
    "    no_data = dataset.GetRasterBand(1).GetNoDataValue()\n",
    "    gdal.Translate(output_path, dataset, outputType=gdal.GDT_Float32, projWin=bounds, projWinSRS='EPSG:4326', noData=no_data)\n",
    "\n",
    "    dataset = None\n",
    "\n",
    "    \n",
    "def write_output_image(filepath, output_matrix, image_format, data_format, mask=None, output_projection=None, output_geotransform=None, no_data_value=None):\n",
    "    driver = gdal.GetDriverByName(image_format)\n",
    "    out_rows = np.size(output_matrix, 0)\n",
    "    out_columns = np.size(output_matrix, 1)\n",
    "    \n",
    "    \n",
    "    if mask is not None and mask is not 0:\n",
    "        # TODO: check if output folder exists\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 2, data_format)\n",
    "        mask_band = output.GetRasterBand(2)\n",
    "        mask_band.WriteArray(mask)\n",
    "        if no_data_value is not None:\n",
    "            output_matrix[mask > 0] = no_data_value\n",
    "    else:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 1, data_format)\n",
    "    \n",
    "    if output_projection is not None:\n",
    "        output.SetProjection(output_projection)\n",
    "    if output_geotransform is not None:\n",
    "        output.SetGeoTransform(output_geotransform)\n",
    "    \n",
    "    raster_band = output.GetRasterBand(1)\n",
    "    if no_data_value is not None:\n",
    "        raster_band.SetNoDataValue(no_data_value)\n",
    "    raster_band.WriteArray(output_matrix)\n",
    "    \n",
    "    if filepath is None:\n",
    "        print  \"filepath\"\n",
    "    if output is None:\n",
    "        print  \"output\"\n",
    "    gdal.Warp(filepath, output, format=\"GTiff\", outputBoundsSRS='EPSG:4326', xRes=output_geotransform[1], yRes=-output_geotransform[5], targetAlignedPixels=True)\n",
    "\n",
    "    return filepath\n",
    "\n",
    "\n",
    "def matrix_multiply(mat1, mat2, no_data_value=None):\n",
    "    #if no_data_value is not None:\n",
    "        #if not isinstance(mat1, int):\n",
    "            #mat1[(mat1 == no_data_value)] = 0\n",
    "        #if not isinstance(mat2, int):\n",
    "            #mat2[(mat2 == no_data_value)] = 0\n",
    "    mats_nodata = np.logical_or(mat1 == no_data_value, mat2 == no_data_value)\n",
    "    mat1 = mat1.astype('float32')\n",
    "    mat2 = mat2.astype('float32')\n",
    "    multiply = mat1 * mat2\n",
    "    multiply = np.where(mats_nodata, no_data_value, multiply)\n",
    "    return multiply\n",
    "            \n",
    "\n",
    "def get_matrix_list(image_list):\n",
    "    projection = None\n",
    "    geo_transform = None\n",
    "    no_data = None\n",
    "    mat_list = []\n",
    "    for img in image_list:\n",
    "        dataset = gdal.Open(img)\n",
    "        print dataset\n",
    "        projection = dataset.GetProjection()\n",
    "        print projection\n",
    "        geo_transform = dataset.GetGeoTransform()\n",
    "        no_data = dataset.GetRasterBand(1).GetNoDataValue()\n",
    "        product_array = dataset.GetRasterBand(1).ReadAsArray()\n",
    "        mat_list.append(product_array)\n",
    "        dataset = None\n",
    "    return mat_list, projection, geo_transform, no_data\n",
    "    \n",
    "def write_outputs(product_name, first_date, last_date, averages, standard_deviation, image_format, projection, geo_transform, no_data_value):\n",
    "    filenames = []\n",
    "    areaofinterest = area_of_interest['value']\n",
    "    filenames.append(product_name + '_averages_' + areaofinterest + '_' + first_date + '_' + last_date + '.tif')\n",
    "    filenames.append(product_name + '_standarddeviation_' + areaofinterest + '_'+ first_date + '_' + last_date + '.tif')\n",
    "\n",
    "    write_output_image(filenames[0], averages, image_format, gdal.GDT_Int16, None, projection, geo_transform, no_data_value)\n",
    "    write_output_image(filenames[1], standard_deviation, image_format, gdal.GDT_Int16, None, projection, geo_transform, no_data_value)\n",
    "    \n",
    "    return filenames\n",
    "\n",
    "def write_properties_file(output_name, first_date, last_date):\n",
    "    \n",
    "    title = 'Output %s' % output_name\n",
    "    \n",
    "    first_date = get_formatted_date(first_date)\n",
    "    last_date = get_formatted_date(last_date)\n",
    "    \n",
    "    with open(output_name + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (first_date, last_date))\n",
    "        file.write('geometry=%s' % (regionOfInterest['value']))\n",
    "        \n",
    "def get_formatted_date(date_obj):\n",
    "    date = datetime.datetime.strftime(date_obj, '%Y-%m-%dT00:00:00Z')\n",
    "    return date\n",
    "\n",
    "def reproject_image_to_master ( master, slave, dst_filename, res=None ):\n",
    "\n",
    "    slave_ds = gdal.Open( slave )\n",
    "    if slave_ds is None:\n",
    "        raise IOError, \"GDAL could not open slave file %s \" \\\n",
    "            % slave\n",
    "    slave_proj = slave_ds.GetProjection()\n",
    "    slave_geotrans = slave_ds.GetGeoTransform()\n",
    "    data_type = slave_ds.GetRasterBand(1).DataType\n",
    "    n_bands = slave_ds.RasterCount\n",
    "    #no_data_value that does not exist on the image\n",
    "    slave_ds.GetRasterBand(1).SetNoDataValue(-300.0)\n",
    "\n",
    "    master_ds = gdal.Open( master )\n",
    "    if master_ds is None:\n",
    "        raise IOError, \"GDAL could not open master file %s \" \\\n",
    "            % master\n",
    "    master_proj = master_ds.GetProjection()\n",
    "    master_geotrans = master_ds.GetGeoTransform()\n",
    "    w = master_ds.RasterXSize\n",
    "    h = master_ds.RasterYSize\n",
    "    \n",
    "    if res is not None:\n",
    "        master_geotrans[1] = float( res )\n",
    "        master_geotrans[-1] = - float ( res )\n",
    "    \n",
    "    dst_ds = gdal.GetDriverByName('GTiff').Create(dst_filename, w, h, n_bands, data_type)\n",
    "    \n",
    "    dst_ds.SetGeoTransform( master_geotrans )\n",
    "    dst_ds.SetProjection( master_proj)\n",
    "    \n",
    "    gdal.ReprojectImage( slave_ds, dst_ds, slave_proj,\n",
    "                         master_proj, gdal.GRA_NearestNeighbour)\n",
    "    \n",
    "    dst_ds = None  # Flush to disk\n",
    "    \n",
    "    return dst_filename\n",
    "\n",
    "def project_coordinates(file, dst_filename):\n",
    "    input_raster = gdal.Open(file)\n",
    "    output_raster = dst_filename \n",
    "    gdal.Warp(output_raster,input_raster,dstSRS='EPSG:4326')\n",
    "    \n",
    "def get_pixel_weights(mat):\n",
    "    urban_fabric=[111.,112.]\n",
    "    industrial_commercial_transport_units=[121.,122.,123.,124.]\n",
    "    mine_dump_construction_sites=[131.,132.,133.]\n",
    "    artificial_areas=[141.,142.]\n",
    "    arable_land=[211.,212.,213.]\n",
    "    permanent_crops=[221.,222.,223.]\n",
    "    pastures=[231.]\n",
    "    agricultural_areas=[241.,242.,243.,244.]\n",
    "    forest=[311.,312.,313.]\n",
    "    vegetation_associations=[321.,322.,323.,324.]\n",
    "    little_no_vegetation=[331.,332.,333.,334.,335.]\n",
    "    inland_wetlands=[411.,412.]\n",
    "    coastal_wetlands=[421.,422.,423.]\n",
    "    inland_waters=[511.,512.]\n",
    "    marine_waters=[521.,522.,523.]\n",
    "\n",
    "    exposure_dictionary = dict()\n",
    "    exposure_dictionary[1.0] = urban_fabric\n",
    "    exposure_dictionary[0.5] = industrial_commercial_transport_units + arable_land + permanent_crops\n",
    "    exposure_dictionary[0.3] = mine_dump_construction_sites + agricultural_areas\n",
    "    exposure_dictionary[0.0] = artificial_areas + marine_waters\n",
    "    exposure_dictionary[0.4] = pastures\n",
    "    exposure_dictionary[0.1] = forest + vegetation_associations + little_no_vegetation + inland_wetlands + coastal_wetlands + inland_waters\n",
    "\n",
    "    rows = mat.shape[0]\n",
    "    cols = mat.shape[1]\n",
    "\n",
    "    for i in range(0, rows):\n",
    "        for j in range(0, cols):\n",
    "            for exposure, value_list in exposure_dictionary.iteritems():\n",
    "                for value in value_list:\n",
    "                    if mat[i,j] == value:\n",
    "                        mat[i,j] = exposure\n",
    "    return mat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(output_folder) > 0:\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "\n",
    "if not os.path.isdir(temp_folder):\n",
    "    os.mkdir(temp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_interest['value'], start_year['value'], end_year['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update AOI if crop not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_year = start_year['value']\n",
    "last_year = end_year['value']\n",
    "product_path_name = output_folder\n",
    "projection = None\n",
    "geo_transform = None\n",
    "no_data = None\n",
    "areaofinterest = area_of_interest['value']\n",
    "\n",
    "if input_identifiers[0] >=0:    \n",
    "        file_list = [os.path.join(etc_path, filename) for filename in input_identifiers]\n",
    "        \n",
    "        flood_frequency = os.path.join(temp_folder, 'flood_frequency_cropped.tif')        \n",
    "        crop_image(file_list[1],regionOfInterest['value'],flood_frequency)\n",
    "        \n",
    "        flood_exposure=file_list[0]\n",
    "        image_list=[flood_exposure,flood_frequency]\n",
    "       \n",
    "        dst_filename = os.path.basename(flood_exposure)\n",
    "        dst_filename = dst_filename.replace(\".tif\", \"_reprojected.tif\" )\n",
    "        dst_filename = os.path.join(temp_folder, dst_filename)\n",
    "        \n",
    "        #co-registration (slave on master)\n",
    "        flood_exposure_reprojected = reproject_image_to_master(flood_frequency, flood_exposure, dst_filename)\n",
    "        image_list=[flood_exposure_reprojected,flood_frequency]\n",
    "        mat_list, projection, geo_transform, no_data=get_matrix_list(image_list) \n",
    "        \n",
    "        flood_frequency_mat = mat_list[1]\n",
    "        flood_exposure_mat = mat_list[0]\n",
    "        no_data=-200.0\n",
    "        flood_hazard = matrix_multiply(flood_frequency_mat,flood_exposure_mat, no_data)\n",
    "        flood_hazard = np.where(flood_exposure==no_data, no_data, flood_hazard)\n",
    "        flood_hazard = np.where(flood_hazard==0.0, no_data, flood_hazard)\n",
    "\n",
    "        file = write_output_image(os.path.join(product_path_name , 'flood_hazard_' + areaofinterest + first_year + last_year + '.tif'), flood_hazard, 'GTiff', gdal.GDT_Float32, None, projection, geo_transform, no_data)\n",
    "        firstdate_obj = datetime.datetime.strptime(first_year, \"%Y\").date()\n",
    "        lastdate_obj = datetime.datetime.strptime(last_year, \"%Y\").date()\n",
    "        \n",
    "else:\n",
    "        print \"error\" + file_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_identifiers[0] >=0:    \n",
    "    if regionOfInterest['value'] == '-1':\n",
    "\n",
    "        #dataset = gdal.Open('/vsigzip//vsicurl/%s' % gpd_final.iloc[0]['enclosure'])\n",
    "        dataset = gdal.Open(file)\n",
    "\n",
    "        geoTransform = dataset.GetGeoTransform()\n",
    "\n",
    "        minx = geoTransform[0]\n",
    "        maxy = geoTransform[3]\n",
    "        maxx = minx + geoTransform[1] * dataset.RasterXSize\n",
    "        miny = maxy + geoTransform[5] * dataset.RasterYSize\n",
    "\n",
    "        regionOfInterest['value'] = 'POLYGON(({0} {1}, {2} {1}, {2} {3}, {0} {3}, {0} {1}))'.format(minx, maxy, maxx, miny)\n",
    "\n",
    "        dataset = None\n",
    "    else:\n",
    "        crop_image(file,regionOfInterest['value'],file.split('.tif')[0] + '_cropped.tif')\n",
    "    \n",
    "    regionofinterest = regionOfInterest['value']\n",
    "    write_properties_file(file, firstdate_obj, lastdate_obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove temporay files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree(temp_folder)\n",
    "    shutil.rmtree(cropped_output_folder)\n",
    "except OSError as e:\n",
    "    print(\"Error: %s : %s\" % (temp_folder, e.strerror))\n",
    "    print(\"Error: %s : %s\" % (cropped_output_folder, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
